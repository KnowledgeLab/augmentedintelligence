{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Week 3 - Augmented Judgment\n",
    "\n",
    "intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#All these packages need to be installed from pip\n",
    "#For ML\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.decomposition\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.datasets import fetch_20newsgroups, make_blobs\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  #Feature extraction\n",
    "from sklearn.naive_bayes import MultinomialNB #Our learner.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#For NLP\n",
    "import nltk\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.parse import stanford\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw.tree import TreeView\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "import numpy as np #arrays\n",
    "import matplotlib.pyplot as plt #Plots\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn #Makes plots look nice, also heatmaps\n",
    "import scipy as sp #for interp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#These are from the standard library\n",
    "import collections\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "import pandas\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "import tarfile\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We also develop a couple of functions for splitting our text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, prob):\n",
    "    \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The Naïve Bayes Classifier\n",
    "\n",
    "## Naive Bayes from Scratch\n",
    "\n",
    "First, let's build a Naive Bayes classifier from scratch to illustrate what's in\n",
    "a classifier. This example is drawn from *Data Science from Scratch* by Joel\n",
    "Grus.\n",
    "\n",
    "### Mathematical Preliminaries\n",
    "\n",
    "Naïve Bayes contains an independence assumption that the probability of features\n",
    "conditional on classification $S$ is equivalent to the product of conditional\n",
    "probabilities associated with each of those features, hence this model's\n",
    "*naïvité*: $P(X_1 = x_1,\\dots,X_n = x_n\\,|\\,S) = P(X_1 = x_1\\,|\\,S)\\times \\dots\n",
    "    \\times P(X_n = x_n\\,|\\,S)$\n",
    "\n",
    "To be concrete, let's assume we are building a spam filter.\n",
    "\n",
    "Given a vocabulary $w_1,\\dots,w_n$, let $X_i$ be the event \"message contains\"\n",
    "$w_i$.\" $X_i = x_i, x_i \\in \\{0,1\\}$.\n",
    "\n",
    "$S$ is the event \"message is spam\" and $\\neg S$ is the event \"message is not\n",
    "spam.\"\n",
    "\n",
    "According to Bayes' Theorem:\n",
    "\n",
    "$P(S\\,|\\,X_1 = x_1,\\dots, X_n = x_n) = \\frac{P(X_1 = x_1,\\dots, X_n =\n",
    "x_n\\,|\\,S)P(S)}{P(X_1 = x_1,\\dots, X_n = x_n)} = \\frac{P(X_1 = x_1,\\dots, X_n =\n",
    "x_n\\,|\\,S)P(S)}{P(X_1 = x_1,\\dots, X_n = x_n\\,|\\,S)P(S)\\, + \\,P(X_1 = x_1,\\dots,\n",
    "X_n = x_n\\,|\\,\\neg S)P(\\neg S)}$\n",
    "\n",
    "We further assume that we have no knowledge of the prior probability of spam; so\n",
    "$P(S) = P(\\neg S) = 0.5$ (this is the principle of indifference)\n",
    "\n",
    "With this simplification, $P(S\\,|\\,X_1 = x_1,\\dots, X_n = x_n) = \\frac{P(X_1 =\n",
    "x_1,\\dots, X_n = x_n\\,|\\,S)}{P(X_1 = x_1,\\dots, X_n = x_n\\,|\\,S)\\, +\\, P(X_1 =\n",
    "x_1,\\dots, X_n = x_n\\,|\\,\\neg S)}$\n",
    "\n",
    "Now we make the Naive Bayes assumption: $P(X_1 = x_1,\\dots,X_n = x_n\\,|\\,S) =\n",
    "P(X_1 = x_1\\,|\\,S)\\times \\dots\n",
    "    \\times P(X_n = x_n\\,|\\,S)$\n",
    "\n",
    "We can estimate $P(X_i = x_i\\,|\\,S)$ by computing the fraction of spam messages\n",
    "containing the word $i$, e.g., Obamacare.\n",
    "\n",
    "Smoothing: $P(X_i\\,|\\,S) = \\frac{(k + \\textrm{number of spams containing}\\,\n",
    "w_i)}{(2k + \\textrm{number of spams})}$\n",
    "\n",
    "\n",
    "\n",
    "### Now, to code this up...\n",
    "\n",
    "Lets start with spam detection, we have data from:\n",
    "https://spamassassin.apache.org/publiccorpus/ in `data/Spam_Data` with the spam\n",
    "in `data/Spam_Data/20021010_spam.tar.bz2` and the non spam in `data/Spam_Data/20021010_easy_ham.tar.bz2` and `data/Spam_Data/20021010_easy_ham.tar.bz2` zip files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loadEmailZip(targetFile, category):\n",
    "    # regex for stripping out the leading \"Subject:\" and any spaces after it\n",
    "    subject_regex = re.compile(r\"^Subject:\\s+\")\n",
    "\n",
    "    #The dict that will become the DataFrame\n",
    "    emailDict = {\n",
    "        'category' : [],\n",
    "        'text' : [],\n",
    "    }\n",
    "    with tarfile.open(targetFile) as tar:\n",
    "        for tarinfo in tar.getmembers():\n",
    "            if tarinfo.isreg():\n",
    "                with tar.extractfile(tarinfo) as f:\n",
    "                    s = f.read().decode('latin1', 'surrogateescape')\n",
    "                    for line in s.split('\\n'):\n",
    "                        if line.startswith(\"Subject:\"):\n",
    "                            #Could also save the subject field\n",
    "                            subject = subject_regex.sub(\"\", line).strip()\n",
    "                            emailDict['text'].append(subject)\n",
    "    emailDict['category'] = [category] * len(emailDict['text'])\n",
    "    return pandas.DataFrame(emailDict)  \n",
    "\n",
    "spamDF = loadEmailZip('data/Spam_Data/20021010_spam.tar.bz2', 'spam')\n",
    "spamDF = spamDF.append(loadEmailZip('data/Spam_Data/20021010_hard_ham.tar.bz2', 'not spam'), ignore_index= True)\n",
    "spamDF = spamDF.append(loadEmailZip('data/Spam_Data/20021010_easy_ham.tar.bz2', 'not spam'), ignore_index= True)\n",
    "spamDF['is_spam'] = [c == 'spam' for c in spamDF['category']]\n",
    "spamDF[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can now tokenize and normalize like normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normlizeTokens(tokenLst, stopwordLst = None, stemmer = None, lemmer = None, vocab = None):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "\n",
    "    #Lowering the case and removing non-words\n",
    "    workingIter = (w.lower() for w in tokenLst if w.isalpha())\n",
    "\n",
    "    #Now we can use the semmer, if provided\n",
    "    if stemmer is not None:\n",
    "        workingIter = (stemmer.stem(w) for w in workingIter)\n",
    "\n",
    "    #And the lemmer\n",
    "    if lemmer is not None:\n",
    "        workingIter = (lemmer.lemmatize(w) for w in workingIter)\n",
    "\n",
    "    #And remove the stopwords\n",
    "    if stopwordLst is not None:\n",
    "        workingIter = (w for w in workingIter if w not in stopwordLst)\n",
    "\n",
    "    #We will return a list with the stopwords removed\n",
    "    if vocab is not None:\n",
    "        vocab_str = '|'.join(vocab)\n",
    "        workingIter = (w for w in workingIter if re.match(vocab_str, w))\n",
    "\n",
    "    return list(workingIter)\n",
    "\n",
    "stop_words_nltk = nltk.corpus.stopwords.words('english')\n",
    "snowball = nltk.stem.snowball.SnowballStemmer('english')\n",
    "\n",
    "spamDF['tokenized_emails'] = spamDF['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "spamDF['normalized_emails'] = spamDF['tokenized_emails'].apply(lambda x: normlizeTokens(x, stopwordLst = None, stemmer = None))\n",
    "spamDF[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we need to count the number of times each word shows up in spam and non-spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def count_words(traingDF, textColumn, trainingColumn):\n",
    "    counts = collections.defaultdict(lambda: [0, 0])\n",
    "    for index, row in traingDF.iterrows():\n",
    "        for word in set(row[textColumn]):\n",
    "            if row[trainingColumn]:\n",
    "                counts[word][0] += 1\n",
    "            else:\n",
    "                counts[word][1] += 1\n",
    "    return counts\n",
    "wordCounts = count_words(spamDF, 'normalized_emails', 'is_spam')\n",
    "wordCounts['cancel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We need a function to convert these counts into (smoothed) probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
    "    \"\"\"turn the word_counts into a list of triplets\n",
    "    w, p(w | spam) and p(w | ~spam)\"\"\"\n",
    "    retTuples = []\n",
    "    for w, (spam, non_spam) in counts.items():\n",
    "        retTuples.append((w,\n",
    "             (spam + k) / (total_spams + 2 * k),\n",
    "             (non_spam + k) / (total_non_spams + 2 * k)))\n",
    "    return retTuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we need to come up with a way to compute the spam probability for a message,\n",
    "given word probabilities. With the Naive Bayes assumption, we *would* be\n",
    "multiplying together a bunch of probabilities. This is bad (e.g., floating point\n",
    "underflow) so we instead compute:\n",
    "\n",
    "$p_1 *\\dots*p_n = \\exp(\\, \\log(p_1) + \\dots + \\log(p_n)\\,)$; recall $\\log(ab) =\n",
    "\\log a + \\log b$ and $\\exp(\\, \\log x \\,) = x$\n",
    "\n",
    "Thank you, John Napier (1550-1617), for inventing logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def spam_probability(word_probs, message_words):\n",
    "    #message_words = tokenize(message)\n",
    "    log_prob_if_spam = log_prob_if_not_spam = 0.0 #Initialize; we are working with log probs to deal with underflow.\n",
    "\n",
    "    for word, prob_if_spam, prob_if_not_spam in word_probs: #We iterate over all possible words we've observed\n",
    "        # for each word in the message,\n",
    "        # add the log probability of seeing it\n",
    "        if word in message_words:\n",
    "            log_prob_if_spam += math.log(prob_if_spam) #This is prob of seeing word if spam\n",
    "            log_prob_if_not_spam += math.log(prob_if_not_spam) #This is prob of seeing word if not spam\n",
    "\n",
    "        # for each word that's not in the message\n",
    "        # add the log probability of _not_ seeing it\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
    "    P = 1/(1 + math.exp(log_prob_if_not_spam - log_prob_if_spam))\n",
    "    #prob_if_spam = math.exp(log_prob_if_spam) #Compute numerator\n",
    "    #prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
    "    #return prob_if_spam / (prob_if_spam + prob_if_not_spam) #Compute whole thing and return\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Think: how would this change if $P(S) \\neq P(\\neg S)$\n",
    "\n",
    "Now we write a class (this is a Python term) for our Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self, k=0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = [] #Initializes word_probs as an empty list, sets a default smoothing parameters\n",
    "\n",
    "    def train(self, training_set, trainingColumn, textColumn): #Operates on the training_set\n",
    "\n",
    "        # count spam and non-spam messages: first step of training\n",
    "        num_spams = training_set[trainingColumn].value_counts()[True]\n",
    "        num_non_spams = len(training_set) - num_spams\n",
    "\n",
    "        # run training data through our \"pipeline\"\n",
    "        word_counts = count_words(training_set, textColumn, trainingColumn)\n",
    "        self.word_probs = word_probabilities(word_counts,\n",
    "                                             num_spams,\n",
    "                                             num_non_spams,\n",
    "                                             self.k) #\"Train\" classifier\n",
    "\n",
    "    def classify(self, message):\n",
    "        return spam_probability(self.word_probs, message) #Now we have all we need to classify a message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To train and then evaluate our model, we will split our data into ***training***\n",
    "& ***testing*** sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "shuffledSpamDF = spamDF.reindex(np.random.permutation(spamDF.index))\n",
    "holdBackFraction = .2\n",
    "holdBackIndex = int(holdBackFraction * len(shuffledSpamDF))\n",
    "train_data = shuffledSpamDF[holdBackIndex:].copy()\n",
    "test_data = shuffledSpamDF[:holdBackIndex].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifier.train(train_data, 'is_spam', 'normalized_emails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Some simple evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# triplets (subject, actual is_spam, predicted spam probability)\n",
    "classified = [(row['category'], classifier.classify(row['normalized_emails']))\n",
    "              for index, row in test_data.iterrows()]\n",
    "\n",
    "# assume that spam_probability > 0.5 corresponds to spam prediction # and count the combinations of (actual is_spam, predicted is_spam)\n",
    "counts = collections.Counter((actual == 'spam', predicted_probability > 0.5)\n",
    "                     for actual, predicted_probability in classified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, let's see how we did! We will do so by computing the Precision, Recall and\n",
    "F-measure or harmonic mean between Precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "precision = counts[(True,True)]/(counts[(False,True)]+counts[(True,True)]) #True positives over all positive predictions\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "recall = counts[(True,True)]/(counts[(True,False)]+counts[(True,True)])#what fraction of positives identified\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "F-measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f_measure = 2 * (precision * recall)/(precision + recall)\n",
    "print (f_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's look at how the emails are classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_data['predicted_spam_probability'] = [classifier.classify(d) for d in test_data['normalized_emails']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we calculate the ROC curve, and integrate to get the area under the curve\n",
    "(AUC), or probability mass associated with correct classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x, y, _ = sklearn.metrics.roc_curve(test_data['is_spam'], test_data['predicted_spam_probability'])\n",
    "roc_auc = sklearn.metrics.auc(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x,y, color = 'darkorange', lw = 2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What will happen if we split the data differently (e.g.,\n",
    "less training data, more testing data).\n",
    "\n",
    "<span style=\"color:red\">**Try it!**\n",
    "\n",
    "We can also find words that lead to a high probability of spam (using Bayes'\n",
    "Theorem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def p_spam_given_word(word_prob):\n",
    "    \"\"\"uses bayes's theorem to compute p(spam | message contains word)\"\"\"\n",
    "    # word_prob is one of the triplets produced by word_probabilities\n",
    "\n",
    "    word, prob_if_spam, prob_if_not_spam = word_prob\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words = sorted(classifier.word_probs,key=p_spam_given_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spammiest_words = words[-15:]\n",
    "hammiest_words = words[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spammiest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hammiest_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Now with a corpus of Clinton / Obama Press Releases\n",
    "\n",
    "While the Clinton and Obama Senatorial Press are not hand-coded, we can imagine\n",
    "that we have been given a stack of such press releases, but lost the metadata\n",
    "associated with which senatorial office issued which. If we label a few of them,\n",
    "how well can our classifier do at recovering the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ObamaClintonReleases = pandas.read_csv(\"data/ObamaClintonReleases.csv\")\n",
    "ObamaClintonReleases = ObamaClintonReleases.dropna(axis=0, how='any')\n",
    "ObamaClintonReleases['tokenized_text'] = ObamaClintonReleases['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "ObamaClintonReleases['normalized_text'] = ObamaClintonReleases['tokenized_text'].apply(lambda x: normlizeTokens(x, stopwordLst = stop_words_nltk, stemmer = snowball))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's turn the 'targetSenator' column into a binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ObamaClintonReleases['IsObama'] = [s == 'Obama' for s in ObamaClintonReleases['targetSenator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's split the data into training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "ObamaClintonReleases = ObamaClintonReleases.reindex(np.random.permutation(ObamaClintonReleases.index))\n",
    "holdBackFraction = .25\n",
    "holdBackIndex = int(holdBackFraction * len(ObamaClintonReleases))\n",
    "train_data = ObamaClintonReleases[holdBackIndex:].copy()\n",
    "test_data = ObamaClintonReleases[:holdBackIndex].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print (len(train_data))\n",
    "print (len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "First, let's try with a logistic regression, which may be familiar to you from\n",
    "statistical methods classes. First, we must turn the training dataset into a tf-\n",
    "idf matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects = TFVectorizer.fit_transform(train_data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that we can use the CountVectorizer instead, which simply produces a matrix\n",
    "of word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFVects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In a regression, we cannot have more variables than cases. So, we need to first\n",
    "do a dimension reduction. First, we will approah this with PCA. You have\n",
    "previously seen this in week 3. Here we are not concerned about visualization\n",
    "but rather classification and so all principal components are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PCA = sklearn.decomposition.PCA\n",
    "pca = PCA().fit(TFVects.toarray())\n",
    "reduced_data = pca.transform(TFVects.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visualization in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "colordict = {\n",
    "True: 'red',\n",
    "False: 'blue',\n",
    "    }\n",
    "colors = [colordict[c] for c in train_data['IsObama']]\n",
    "fig = plt.figure(figsize = (5,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "ax.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors, alpha = 0.5, label = colors)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('True Classes, Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "PCA cannot distinguish Clinton from Obama very well. Let's perform a screeplot\n",
    "to see how many dimensions we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n = TFVects.shape[0]\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "eigen_vals = np.arange(n) + 1\n",
    "ax1.plot(eigen_vals, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "ax1.set_title('Scree Plot')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "eigen_vals = np.arange(20) + 1\n",
    "ax2.plot(eigen_vals, pca.explained_variance_ratio_[:20], 'ro-', linewidth=2)\n",
    "ax2.set_title('Scree Plot (First 20 Principal Components)')\n",
    "ax2.set_xlabel('Principal Component')\n",
    "ax2.set_ylabel('Proportion of Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's choose the first 10 pricipal components as our covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = reduced_data[:, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Transform our predictor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y = np.array([int(label) for label in train_data['IsObama']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we fit a logistic regression to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's see how the logistic regression performs on the training dataset on we\n",
    "develop the model. Unfortunately, mean accuracy is only about 68%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logistic.score(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "How does it perform on the testing dataset, which we \"held out\" and did not use\n",
    "for model training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFVects_test = TFVectorizer.transform(test_data['text'])\n",
    "reduced_data_test = pca.transform(TFVects_test.toarray())\n",
    "X_test = reduced_data_test[:, :10]\n",
    "Y_test = np.array([int(label) for label in test_data['IsObama']])\n",
    "logistic.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Slightly poorer. How about using more dimensions (40)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = reduced_data[:, :40]\n",
    "logistic.fit(X, Y)\n",
    "X_test = reduced_data_test[:, :40]\n",
    "print(logistic.score(X,Y))\n",
    "print(logistic.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or still more (100)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = reduced_data[:, :100]\n",
    "logistic.fit(X, Y)\n",
    "X_test = reduced_data_test[:, :100]\n",
    "print(logistic.score(X,Y))\n",
    "print(logistic.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or even more (200)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = reduced_data[:, :200]\n",
    "logistic.fit(X, Y)\n",
    "X_test = reduced_data_test[:, :200]\n",
    "print(logistic.score(X,Y))\n",
    "print(logistic.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is becoming ridiculous (400)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = reduced_data[:, :400]\n",
    "logistic.fit(X, Y)\n",
    "X_test = reduced_data_test[:, :400]\n",
    "print(logistic.score(X,Y))\n",
    "print(logistic.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Increasing the number of covariates would overfit our data, and it seems that\n",
    "using a logistic regression, our prediction accuracy is at best about 80%. We\n",
    "can, however, try a logistic regression that uses L1 regularization or the\n",
    "L1-norm loss function, which is also known as least absolute deviations (LAD),\n",
    "least absolute errors (LAE) or L1 penalty. It minimizes the sum of the absolute\n",
    "differences (S) between the target value ($Y_i$) and the estimated values\n",
    "($f(x_i)$):\n",
    "\n",
    "$S=\\sum^n_{i=1}|y_i=f(x_i)|$\n",
    "\n",
    "The result is a model retaining only the most individually significant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = TFVects\n",
    "logistic_l1= linear_model.LogisticRegression(penalty='l1')\n",
    "logistic_l1.fit(X, Y)\n",
    "print(logistic_l1.score(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train the model using training data, and then test it on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(logistic_l1.score(TFVects_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "84% accuracy seems like the best we can get by using a logistic regression.\n",
    "\n",
    "Now let's try with Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#wc = wordCounts(train_data, 'normalized_text')\n",
    "wc = count_words(train_data, 'normalized_text', 'IsObama')\n",
    "wc['veteran']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier()\n",
    "classifier.train(train_data, 'IsObama', 'normalized_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's evaluate the result on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classified = []\n",
    "for index, row in test_data.iterrows():\n",
    "    classified.append((row['normalized_text'], row['IsObama'], classifier.classify(row['normalized_text'])))\n",
    "\n",
    "# assume that spam_probability > 0.5 corresponds to spam prediction # and count the combinations of (actual is_spam, predicted is_spam)\n",
    "counts = collections.Counter((actual, predicted_probability > 0.5)\n",
    "                     for text, actual, predicted_probability in classified)\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "precision = counts[(True,True)]/(counts[(False,True)]+counts[(True,True)]) #True positives over all positive predictions\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "recall = counts[(True,True)]/(counts[(True,False)]+counts[(True,True)])#what fraction of positives identified\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "F-measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f_measure = 2 * (precision * recall)/(precision + recall)\n",
    "print (f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_classification = pandas.DataFrame(classified, columns = ['press release', 'is Obama', 'posterior probability'])\n",
    "df_classification = df_classification.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's take a look at how well our posterior distribution looks relative to the\n",
    "truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.grid(False)\n",
    "ax1.set_frame_on(False)\n",
    "df_classification[df_classification['is Obama'] == True]['posterior probability'].hist(alpha = 0.5, ax = ax1, bins = 10, label = 'Obama', color = 'red')\n",
    "df_classification[df_classification['is Obama'] == False]['posterior probability'].hist(alpha = 0.5, ax = ax1, bins = 10, label = 'Clinton', color = 'blue')\n",
    "ax1.set_xlim((0,1.1))\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('posterior')\n",
    "ax1.set_ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The classification is suprisingly accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def p_obama_given_word(word_prob):\n",
    "    \"\"\"uses bayes's theorem to compute p(spam | message contains word)\"\"\"\n",
    "    # word_prob is one of the triplets produced by word_probabilities\n",
    "\n",
    "    word, prob_if_obama, prob_if_not_obama = word_prob\n",
    "    return prob_if_obama / (prob_if_obama + prob_if_not_obama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words = sorted(classifier.word_probs,key=p_obama_given_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Obama_words = words[-15:]\n",
    "Clinton_words = words[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What are the words that distinguish Obama and Clinton press releases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Obama_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Clinton_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Multinomial Naive Bayes\n",
    "\n",
    "What if we want to classify our text into one of *many* classes? The multinomial\n",
    "Naive Bayes generating model assumes that document features (e.g., words) are\n",
    "generated by draws from a multinomial distribution (recall this gives the\n",
    "probability to observe a particular pattern of counts across features).\n",
    "\n",
    "Let's use again the dataset we used in week 3, the 20 newsgroup dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(data_home = 'data') #Free data to play with: documents from a newsgroup corpus.\n",
    "data.target_names #Possible categories, i.e., the newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This dataset has a built in breakdown into training and testing sets. We can\n",
    "pick specific categories, and pull the relevant training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "categories = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics'] #Can change these of course\n",
    "train = fetch_20newsgroups(subset='train', categories=categories, data_home = 'data')\n",
    "test = fetch_20newsgroups(subset='test', categories=categories, data_home = 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(train.data) #See how many training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(test.data) #Ditto for testing -- it's about 60% training, 40% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(train.data[5]) #Look at an example\n",
    "#print(train.target_names[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We need to extract features from the text. We can use built-in feature\n",
    "extraction to do so. We will use a tf-idf vectorizer, which converts the\n",
    "document into a vector of words with tf-idf weights (term-frequency inverse-\n",
    "document frequency). This gives high weight to words that show up a lot in a\n",
    "given document but rarely across documents in the corpus (more distinctive).\n",
    "\n",
    "We also take advantage of a useful feature of Scikit-Learn: we can make\n",
    "pipelines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2'), MultinomialNB()) #This applies the vectorizer, then trains Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit(train.data,train.target) #Training syntax: feed the fit method the training data and the training targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = model.predict(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can even use a confusion matrix, like we used last week for evaluating human\n",
    "coders relative to one another. Now we are evaluating our classifier relative to\n",
    "human coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test.target, labels)\n",
    "seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=train.target_names, yticklabels=train.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's calculate the precision, recall, and F-measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.precision_score(test.target, labels, average = 'weighted')) #precision\n",
    "print(sklearn.metrics.recall_score(test.target, labels, average = 'weighted')) #recall\n",
    "print(sklearn.metrics.f1_score(test.target, labels, average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Get the ROC curves.\n",
    "First, we need to binarize the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(test.target)\n",
    "print(lb.classes_)\n",
    "print(lb.transform([1, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_test = lb.transform(test.target)\n",
    "y_score = model.predict_proba(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = sklearn.metrics.roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = sklearn.metrics.roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = sklearn.metrics.auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lw = 2\n",
    "n_classes = 4\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += sp.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] =  sklearn.metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue', 'olive']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also give the model a string and use the predict method to see if it can\n",
    "assign it to a category. Using our model to extend to new, uncoded data might be\n",
    "the primary purpose of a social science application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_category(s, train=train, model=model): #We just define a simple function here\n",
    "    return train.target_names[model.predict([s])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#predict_category('rockets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Try it yourself with your own strings!\n",
    "\n",
    "\n",
    "## Now let's add Bernie Sanders to our Obama / Clinton face-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ObamaClintonSandersReleases = pandas.read_csv(\"data/ObamaClintonSandersReleases.csv\")\n",
    "ObamaClintonSandersReleases = ObamaClintonSandersReleases.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's split the data into training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = list(zip(ObamaClintonSandersReleases['text'], ObamaClintonSandersReleases['targetSenator']))\n",
    "random.seed(0) #This is important for replicability\n",
    "train_data,test_data = split_data(data,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print (len(train_data))\n",
    "print (len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train.data = [data[0] for data in train_data]\n",
    "train.target = [data[1] for data in train_data]\n",
    "test.data = [data[0] for data in test_data]\n",
    "test.target = [data[1] for data in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit(train.data,train.target) #Training syntax: feed the fit method the training data and the training targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = model.predict(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test.target, labels)\n",
    "seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=['Obama', 'Clinton', 'Sanders'], yticklabels=['Obama', 'Clinton', 'Sanders'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's get the precision, recall, and F-measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.precision_score(test.target, labels, average = 'weighted')) #precision\n",
    "print(sklearn.metrics.recall_score(test.target, labels, average = 'weighted')) #recall\n",
    "print(sklearn.metrics.f1_score(test.target, labels, average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In order to get the ROC curves, first we need to binarize the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(test.target)\n",
    "print(lb.classes_)\n",
    "print(lb.transform(['Clinton', 'Obama']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_test = lb.transform(test.target)\n",
    "y_score = model.predict_proba(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = sklearn.metrics.roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = sklearn.metrics.roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = sklearn.metrics.auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += sp.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] =  sklearn.metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also give the model a string and use the predict method assign it to a\n",
    "category. This extrapolation to new, untagged data will likely be the main point\n",
    "of a social science application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.predict(['money'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.predict(['Wall Street'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.predict(['Chicago'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Decision Trees\n",
    "\n",
    "We now return to the python Machine learning package, Scikit-Learn, for a\n",
    "decision tree example. Decision trees can be used to predict both\n",
    "categorical/class labels (i.e., classification) and continuous labels (i.e.,\n",
    "regression).\n",
    "\n",
    "To illustrate how these work, we first create some artificial data to learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=300, centers=4,\n",
    "                random_state=0, cluster_std=1.0)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we import our Decision Tree classifier from sklearn.tree (familiar syntax)\n",
    "and fit it using the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4,random_state=0).fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To see what's going on visually with the classification, we can use this\n",
    "(complex) visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def visualize_classifier(model, X, y, Xmod, ymod, ax=None, cmap='rainbow'): #X and y are plotted; Xmod and ymod train\n",
    "    ax = ax or plt.gca()\n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    # fit the estimator\n",
    "    model.fit(Xmod, ymod)\n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    # Create a color plot with the results\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap=cmap, clim=(y.min(), y.max()),\n",
    "                           zorder=1)\n",
    "    ax.set(xlim=xlim, ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xnew, ynew = make_blobs(n_samples=1000, centers=4,\n",
    "                random_state=0, cluster_std=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "visualize_classifier(DecisionTreeClassifier(max_depth=4,random_state=0), Xnew, ynew, X, y) #We train on the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(ynew,DecisionTreeClassifier(max_depth=10,random_state=0).fit(X,y).predict(Xnew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "depthvec = []\n",
    "scorevec = []\n",
    "for i in range(1,20):\n",
    "    tree2 = DecisionTreeClassifier(max_depth=i,random_state=0).fit(X,y)\n",
    "    score = accuracy_score(ynew,tree2.predict(Xnew))\n",
    "    depthvec.append(i)\n",
    "    scorevec.append(score)\n",
    "plt.scatter(depthvec,scorevec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We an select different layers of the tree or \"prune\" the decision tree. At\n",
    "approximately four layers down the decision tree, the shape is somewhat odd,\n",
    "suggesting that our model is overfitting beyond those four layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5,random_state=1) #test_size means a 50/50 split\n",
    "print(len(X))\n",
    "print(len(Xtrain))\n",
    "print(len(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With some abuse of notation, we can use the visualizer to plot first a\n",
    "classifier trained on the \"training\" half of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "visualize_classifier(DecisionTreeClassifier(max_depth=5,random_state=0), X, y, Xtrain, ytrain) #Train with half the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can train on the second half of the data--allegedly the test data--to see\n",
    "how different training sets affect the decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "visualize_classifier(DecisionTreeClassifier(random_state=0), X, y, Xtest, ytest) #Train with other half of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, we can get a sense of the performance by training on the training data,\n",
    "but PLOTTING the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "visualize_classifier(DecisionTreeClassifier(), Xtest, ytest, Xtrain, ytrain) #Trains with train data, plots test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Combining multiple overfitting estimators turns out to be a key idea in machine\n",
    "learning. This is called **bagging** and is a type of **ensemble** method. The\n",
    "idea is to make many randomized estimators--each can overfit, as decision trees\n",
    "are wont to do--but then to combine them, ultimately producing a better\n",
    "classification. A **random forest** is produced by bagging decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10) #Create an instance of our decision tree classifier.\n",
    "\n",
    "bag = BaggingClassifier(tree, n_estimators=100, max_samples=0.8, random_state=1) #Each tree uses up to 80% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#?BaggingClassifier #Learn more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bag.fit(X,y) #Fit the bagged classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xnew, ynew = make_blobs(n_samples=10000, centers=4,\n",
    "                random_state=0, cluster_std=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "visualize_classifier(bag,Xnew,ynew,X,y) #And visualize\n",
    "#Remember we can give the full data as training data, as bag automatically splits and trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "recall_score(ynew,bag.predict(Xnew),average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Let's try this on the Clinton / Obama / Sanders dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFVects = TFVectorizer.fit_transform(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4,random_state=0).fit(TFVects,train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFVects_test = TFVectorizer.transform(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = tree.predict(TFVects_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test.target, labels)\n",
    "seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=['Obama', 'Clinton', 'Sanders'], yticklabels=['Obama', 'Clinton', 'Sanders'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The precision, recall, and F-measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.precision_score(test.target, labels, average = 'weighted')) #precision\n",
    "print(sklearn.metrics.recall_score(test.target, labels, average = 'weighted')) #recall\n",
    "print(sklearn.metrics.f1_score(test.target, labels, average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The decision tree is not substantially better than Multinomial Naive Bayes.\n",
    "Let's try a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bag.fit(TFVects,train.target) #Fit the bagged classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = bag.predict(TFVects_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test.target, labels)\n",
    "seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=['Obama', 'Clinton', 'Sanders'], yticklabels=['Obama', 'Clinton', 'Sanders'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.precision_score(test.target, labels, average = 'weighted')) #precision\n",
    "print(sklearn.metrics.recall_score(test.target, labels, average = 'weighted')) #recall\n",
    "print(sklearn.metrics.f1_score(test.target, labels, average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The performance is better!\n",
    "\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "\n",
    "The K-Nearest neighbors classifier takes a simpler premise than those before:\n",
    "Find the labeled datapoint in question and \"borrow\" its label.\n",
    "\n",
    "Let's use newsgroup data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "categories = ['soc.religion.christian', 'sci.space', 'comp.graphics'] #Can change these of course\n",
    "train = fetch_20newsgroups(subset='train', categories=categories, data_home = 'data')\n",
    "test = fetch_20newsgroups(subset='test', categories=categories, data_home = 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's visualize it using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, min_df=3, stop_words='english', norm='l2')\n",
    "TFVects = TFVectorizer.fit_transform(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFVects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reduced_data = PCA(n_components = 2).fit_transform(TFVects.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "colordict = {\n",
    "0: 'red',\n",
    "1: 'orange',\n",
    "2: 'green',\n",
    "    }\n",
    "colors = [colordict[c] for c in train.target]\n",
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "ax.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors, alpha = 0.5, label = colors)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('True Classes, Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's initialize our k-nearest neighbors classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "weights=\"uniform\"\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For visualization purpopose, let's first try applying the k-nearest neighbors\n",
    "classifier to the projected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.fit(reduced_data, train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFVects_test = TFVectorizer.transform(test.data)\n",
    "reduced_data_test = PCA(n_components = 2).fit_transform(TFVects_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = clf.predict(reduced_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test.target, labels)\n",
    "seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The precision, recall, and F-measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.precision_score(test.target, labels, average = 'weighted')) #precision\n",
    "print(sklearn.metrics.recall_score(test.target, labels, average = 'weighted')) #recall\n",
    "print(sklearn.metrics.f1_score(test.target, labels, average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "x_min, x_max = reduced_data[:, 0].min() - 0.2, reduced_data[:, 0].max() + 0.2\n",
    "y_min, y_max = reduced_data[:, 1].min() - 0.2, reduced_data[:, 1].max() + 0.2\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=colors, cmap=cmap_bold)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "          % (n_neighbors, weights))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's use the full tf-idf matrix instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.fit(TFVects, train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = clf.predict(TFVects_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test.target, labels)\n",
    "seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Small improvement. In this case, PCA reduced the dimensionality of the data\n",
    "without loosing too much informatin.\n",
    "Finally, let's use it again on the Obama Clinton Sanders dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train.data = [data[0] for data in train_data]\n",
    "train.target = [data[1] for data in train_data]\n",
    "test.data = [data[0] for data in test_data]\n",
    "test.target = [data[1] for data in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TFVects_OCS = TFVectorizer.fit_transform(train.data)\n",
    "TFVects_OCS_test = TFVectorizer.transform(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.fit(TFVects_OCS,train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = clf.predict(TFVects_OCS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test.target, labels)\n",
    "seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=['Obama', 'Clinton', 'Sanders'], yticklabels=['Obama', 'Clinton', 'Sanders'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.precision_score(test.target, labels, average = 'weighted')) #precision\n",
    "print(sklearn.metrics.recall_score(test.target, labels, average = 'weighted')) #recall\n",
    "print(sklearn.metrics.f1_score(test.target, labels, average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SVMs\n",
    "\n",
    "Now we will examine Support Vector Machines, an approach that creates the\n",
    "partition that preserves the maximum margin between classes.\n",
    "\n",
    "We will use a few sub forums from reddit--which tend to share text rather than\n",
    "memes--namely `talesfromtechsupport`, `badroommates`, `weeabootales` and\n",
    "`relationships`. The top 100 text posts from each have been saved to\n",
    "`data/reddit.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditDf = pandas.read_csv('data/reddit.csv')\n",
    "\n",
    "#Drop a couple missing values\n",
    "\n",
    "redditDf = redditDf.dropna()\n",
    "\n",
    "#tokenize and normalize\n",
    "redditDf['tokenized_text'] = redditDf['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "redditDf['normalized_text'] = redditDf['tokenized_text'].apply(lambda x: normlizeTokens(x, stopwordLst = stop_words_nltk, stemmer = snowball))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will tf.idf the data to make our vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, min_df=3, stop_words='english', norm='l2')\n",
    "redditTFVects = redditTFVectorizer.fit_transform([' '.join(l) for l in redditDf['normalized_text']])\n",
    "redditDf['tfVect'] = [np.array(v) for v in redditTFVects.todense()]\n",
    "redditDf['tfVect'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditDf['tfVect'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Initilize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = sklearn.svm.SVC(kernel='linear', probability = False)\n",
    "#probability = True is slower but  lets you call predict_proba()\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Setup a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "shuffled_redditDf = redditDf.reindex(np.random.permutation(redditDf.index))\n",
    "holdBackFraction = .2\n",
    "holdBackIndex = int(holdBackFraction * len(shuffled_redditDf))\n",
    "training_redditDf = shuffled_redditDf[holdBackIndex: ].copy()\n",
    "test_redditDf = shuffled_redditDf[:holdBackIndex].copy()\n",
    "print(len(training_redditDf))\n",
    "print(len(test_redditDf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.fit(np.stack(training_redditDf['tfVect'], axis=1)[0], training_redditDf['subreddit'].as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here are the 4 classes of posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And a prediction from the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(clf.predict_proba(test_redditDf['tfVect'][82]))\n",
    "print(clf.predict(test_redditDf['tfVect'][82]))\n",
    "print(test_redditDf['subreddit'][82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditDf['svc'] = [clf.predict(v)[0] for v in redditDf['tfVect']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(redditDf['svc'], redditDf['subreddit'])\n",
    "seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=redditDf['subreddit'].unique(), yticklabels=redditDf['subreddit'].unique())\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural Nets\n",
    "\n",
    "We include an example of a simple neural network, the Multi-layer Perceptron\n",
    "(MLP) that learns a function $f(\\cdot): R^m \\rightarrow R^o$ by training on a\n",
    "dataset, where $m$ is the number of dimensions for input and $o$ is the number\n",
    "of dimensions for output. Given a set of features $X = {x_1, x_2, ..., x_m}$ and\n",
    "a target $y$, it can learn a non-linear function approximator for either\n",
    "classification or regression. It is different from logistic regression, in that\n",
    "between the input and the output layer, there can be one or more non-linear\n",
    "layers, called hidden layers. The following figure shows a one hidden layer MLP\n",
    "with scalar output. ![title](data/multilayerperceptron_network.png) The leftmost\n",
    "layer, known as the input layer, consists of a set of \"neurons\" $\\{x_i | x_1,\n",
    "x_2, ..., x_m\\}$ representing the input features (e.g., weighted words). Each\n",
    "neuron in the hidden layer transforms the values from the previous layer with a\n",
    "weighted linear summation $w_1x_1 + w_2x_2 + ... + w_mx_m$, followed by a non-\n",
    "linear activation function $g(\\cdot):R \\rightarrow R$ - like the logistic or\n",
    "hyperbolic tan function. The output layer receives the values from the last\n",
    "hidden layer and transforms them into output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.fit(np.stack(training_redditDf['tfVect'], axis=1)[0], training_redditDf['subreddit'].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(clf.predict_proba(test_redditDf['tfVect'][82]))\n",
    "print(clf.predict(test_redditDf['tfVect'][82]))\n",
    "print(test_redditDf['subreddit'][82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_redditDf['MLP'] = [clf.predict(v)[0] for v in test_redditDf['tfVect']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test_redditDf['MLP'], test_redditDf['subreddit'])\n",
    "seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=redditDf['subreddit'].unique(), yticklabels=redditDf['subreddit'].unique())\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# NLP\n",
    "\n",
    "We will be using [`nltk`](http://www.nltk.org/) for this notebook this is fine for an introduction but the state of the are implementations are done by the [Stanford NLP group](http://nlp.stanford.edu/). These can even be integrated into Python but are much slower and computationally intensive, for more on integrating look [here](https://github.com/KnowledgeLab/content_analysis/blob/release/7-Information-Extraction/7-Information-Extraction.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "First, we will illustrate these tools on some *very* short examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw the elephant in my pajamas.\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.\n",
      "Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.\n",
      "Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo\n"
     ]
    }
   ],
   "source": [
    "text = ['I saw the elephant in my pajamas.', 'The quick brown fox jumped over the lazy dog.', 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.', 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.', 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']\n",
    "tokenized_text = [word_tokenize(t) for t in text]\n",
    "print('\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part-of-Speech (POS) tagging\n",
    "\n",
    "In POS tagging, we classify each word by its semantic role in a sentence. The\n",
    "Stanford POS tagger uses the [Penn Treebank tag set]('http://repository.upenn.ed\n",
    "u/cgi/viewcontent.cgi?article=1603&context=cis_reports') to POS tag words from\n",
    "input sentences. As discussed in the second assignment, this is a relatively\n",
    "precise tagset, which allows more informative tags, and also more opportunities\n",
    "to err :-).\n",
    "\n",
    "|#. |Tag |Description |\n",
    "|---|----|------------|\n",
    "|1.     |CC     |Coordinating conjunction\n",
    "|2.     |CD     |Cardinal number\n",
    "|3.     |DT     |Determiner\n",
    "|4.     |EX     |Existential there\n",
    "|5.     |FW     |Foreign word\n",
    "|6.     |IN     |Preposition or subordinating conjunction\n",
    "|7.     |JJ     |Adjective\n",
    "|8.     |JJR|   Adjective, comparative\n",
    "|9.     |JJS|   Adjective, superlative\n",
    "|10.|   LS      |List item marker\n",
    "|11.|   MD      |Modal\n",
    "|12.|   NN      |Noun, singular or mass\n",
    "|13.|   NNS     |Noun, plural\n",
    "|14.|   NNP     |Proper noun, singular\n",
    "|15.|   NNPS|   Proper noun, plural\n",
    "|16.|   PDT     |Predeterminer\n",
    "|17.|   POS     |Possessive ending\n",
    "|18.|   PRP     |Personal pronoun\n",
    "|19.|   PRP\\$|  Possessive pronoun\n",
    "|20.|   RB      |Adverb\n",
    "|21.|   RBR     |Adverb, comparative\n",
    "|22.|   RBS     |Adverb, superlative\n",
    "|23.|   RP      |Particle\n",
    "|24.|   SYM     |Symbol\n",
    "|25.|   TO      |to\n",
    "|26.|   UH      |Interjection\n",
    "|27.|   VB      |Verb, base form\n",
    "|28.|   VBD     |Verb, past tense\n",
    "|29.|   VBG     |Verb, gerund or present participle\n",
    "|30.|   VBN     |Verb, past participle\n",
    "|31.|   VBP     |Verb, non-3rd person singular present\n",
    "|32.|   VBZ     |Verb, 3rd person singular present\n",
    "|33.|   WDT     |Wh-determiner\n",
    "|34.|   WP      |Wh-pronoun\n",
    "|35.|   WP$     |Possessive wh-pronoun\n",
    "|36.|   WRB     |Wh-adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('saw', 'VBD'), ('the', 'DT'), ('elephant', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('pajamas', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
      "[('While', 'IN'), ('in', 'IN'), ('France', 'NNP'), (',', ','), ('Christine', 'NNP'), ('Lagarde', 'NNP'), ('discussed', 'VBD'), ('short-term', 'JJ'), ('stimulus', 'NN'), ('efforts', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('recent', 'JJ'), ('interview', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Wall', 'NNP'), ('Street', 'NNP'), ('Journal', 'NNP'), ('.', '.')]\n",
      "[('Trayvon', 'NNP'), ('Benjamin', 'NNP'), ('Martin', 'NNP'), ('was', 'VBD'), ('an', 'DT'), ('African', 'JJ'), ('American', 'JJ'), ('from', 'IN'), ('Miami', 'NNP'), ('Gardens', 'NNP'), (',', ','), ('Florida', 'NNP'), (',', ','), ('who', 'WP'), (',', ','), ('at', 'IN'), ('17', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('was', 'VBD'), ('fatally', 'RB'), ('shot', 'VBN'), ('by', 'IN'), ('George', 'NNP'), ('Zimmerman', 'NNP'), (',', ','), ('a', 'DT'), ('neighborhood', 'NN'), ('watch', 'NN'), ('volunteer', 'NN'), (',', ','), ('in', 'IN'), ('Sanford', 'NNP'), (',', ','), ('Florida', 'NNP'), ('.', '.')]\n",
      "[('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "nltk.pos_tag('a bird')\n",
    "\n",
    "pos_sents = [nltk.pos_tag(s) for s in tokenized_text]\n",
    "for s in pos_sents:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This looks quite good. Now we will try POS tagging with a somewhat larger\n",
    "corpus. We consider a few of the top posts from the reddit data we used last\n",
    "week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditDF = pandas.read_csv('data/reddit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Grabbing the 10 highest scoring posts and tokenizing the sentences. Once again,\n",
    "notice that we aren't going to do any kind of stemming this week (although\n",
    "*semantic* normalization may be performed where we translate synonyms into the\n",
    "same focal word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>over_18</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>brenkelieshere</td>\n",
       "      <td>False</td>\n",
       "      <td>9448</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Last year, Help Desk got a call from a user co...</td>\n",
       "      <td>How to fix a laptop that won't boot in under a...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[Last, year, ,, Help, Desk, got, a, call, fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>Bombadils</td>\n",
       "      <td>False</td>\n",
       "      <td>10528</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>First post in quite some time! I work at a loc...</td>\n",
       "      <td>OK, now the password is 'D35p41r'</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[First, post, in, quite, some, time, !], [I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1200</td>\n",
       "      <td>whenlifegivesyoushit</td>\n",
       "      <td>False</td>\n",
       "      <td>11003</td>\n",
       "      <td>Relationships</td>\n",
       "      <td>[Original Post](https://www.reddit.com/r/relat...</td>\n",
       "      <td>[UPDATE]My [26 F] with my husband [29 M] 1 yea...</td>\n",
       "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
       "      <td>[[[, Original, Post, ], (, https, :, //www.red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>sfsdfd</td>\n",
       "      <td>False</td>\n",
       "      <td>11295</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>I witnessed this astounding IT meltdown around...</td>\n",
       "      <td>Company-wide email + 30,000 employees + auto-r...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[I, witnessed, this, astounding, IT, meltdown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Raitaro</td>\n",
       "      <td>False</td>\n",
       "      <td>12372</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>I work Helpdesk for a retail store chain in th...</td>\n",
       "      <td>I'm pretty sure I knocked a user out from near...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[I, work, Helpdesk, for, a, retail, store, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>goldie-gold</td>\n",
       "      <td>False</td>\n",
       "      <td>12650</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>This just happened...  So, I had a laptop syst...</td>\n",
       "      <td>Engineer is doing drugs!! No. No they aren't.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[This, just, happened, ...], [So, ,, I, had, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TheDroolinFool</td>\n",
       "      <td>False</td>\n",
       "      <td>13152</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Another tale from the out of hours IT desk... ...</td>\n",
       "      <td>\"I need you to fix Google Bing immediately!\"</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[Another, tale, from, the, out, of, hours, IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Clickity_clickity</td>\n",
       "      <td>False</td>\n",
       "      <td>13404</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>[Part 1](http://www.reddit.com/r/talesfromtech...</td>\n",
       "      <td>Jack, the Worst End User, Part 4</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[[, Part, 1, ], (, http, :, //www.reddit.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SECGaz</td>\n",
       "      <td>False</td>\n",
       "      <td>13724</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>&gt; $Me  - Hello, IT.   &gt; $Usr - Hi, I am still ...</td>\n",
       "      <td>Hi, I am still off sick but I am not.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[&gt;, $, Me, -, Hello, ,, IT, .], [&gt;, $, Usr, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>guitarsdontdance</td>\n",
       "      <td>False</td>\n",
       "      <td>14089</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>So my story starts on what was a normal day ta...</td>\n",
       "      <td>\"Don't bother sending a tech, I'll be dead by ...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[So, my, story, starts, on, what, was, a, nor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                author over_18  score                subreddit  \\\n",
       "9           8        brenkelieshere   False   9448  Tales From Tech Support   \n",
       "8           7             Bombadils   False  10528  Tales From Tech Support   \n",
       "7        1200  whenlifegivesyoushit   False  11003            Relationships   \n",
       "6           6                sfsdfd   False  11295  Tales From Tech Support   \n",
       "5           5               Raitaro   False  12372  Tales From Tech Support   \n",
       "4           4           goldie-gold   False  12650  Tales From Tech Support   \n",
       "3           3        TheDroolinFool   False  13152  Tales From Tech Support   \n",
       "2           2     Clickity_clickity   False  13404  Tales From Tech Support   \n",
       "1           1                SECGaz   False  13724  Tales From Tech Support   \n",
       "0           0      guitarsdontdance   False  14089  Tales From Tech Support   \n",
       "\n",
       "                                                text  \\\n",
       "9  Last year, Help Desk got a call from a user co...   \n",
       "8  First post in quite some time! I work at a loc...   \n",
       "7  [Original Post](https://www.reddit.com/r/relat...   \n",
       "6  I witnessed this astounding IT meltdown around...   \n",
       "5  I work Helpdesk for a retail store chain in th...   \n",
       "4  This just happened...  So, I had a laptop syst...   \n",
       "3  Another tale from the out of hours IT desk... ...   \n",
       "2  [Part 1](http://www.reddit.com/r/talesfromtech...   \n",
       "1  > $Me  - Hello, IT.   > $Usr - Hi, I am still ...   \n",
       "0  So my story starts on what was a normal day ta...   \n",
       "\n",
       "                                               title  \\\n",
       "9  How to fix a laptop that won't boot in under a...   \n",
       "8                  OK, now the password is 'D35p41r'   \n",
       "7  [UPDATE]My [26 F] with my husband [29 M] 1 yea...   \n",
       "6  Company-wide email + 30,000 employees + auto-r...   \n",
       "5  I'm pretty sure I knocked a user out from near...   \n",
       "4      Engineer is doing drugs!! No. No they aren't.   \n",
       "3       \"I need you to fix Google Bing immediately!\"   \n",
       "2                   Jack, the Worst End User, Part 4   \n",
       "1              Hi, I am still off sick but I am not.   \n",
       "0  \"Don't bother sending a tech, I'll be dead by ...   \n",
       "\n",
       "                                                 url  \\\n",
       "9  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "8  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "7  https://www.reddit.com/r/relationships/comment...   \n",
       "6  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "5  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "4  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "3  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "2  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "1  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "0  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "\n",
       "                                           sentences  \n",
       "9  [[Last, year, ,, Help, Desk, got, a, call, fro...  \n",
       "8  [[First, post, in, quite, some, time, !], [I, ...  \n",
       "7  [[[, Original, Post, ], (, https, :, //www.red...  \n",
       "6  [[I, witnessed, this, astounding, IT, meltdown...  \n",
       "5  [[I, work, Helpdesk, for, a, retail, store, ch...  \n",
       "4  [[This, just, happened, ...], [So, ,, I, had, ...  \n",
       "3  [[Another, tale, from, the, out, of, hours, IT...  \n",
       "2  [[[, Part, 1, ], (, http, :, //www.reddit.com/...  \n",
       "1  [[>, $, Me, -, Hello, ,, IT, .], [>, $, Usr, -...  \n",
       "0  [[So, my, story, starts, on, what, was, a, nor...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores = redditDF.sort_values('score')[-10:]\n",
    "redditTopScores['sentences'] = redditTopScores['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "redditTopScores.index = range(len(redditTopScores) - 1, -1,-1) #Reindex to make things nice in the future\n",
    "redditTopScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['POS_sents'] = redditTopScores['sentences'].apply(lambda x: [nltk.pos_tag(s) for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, JJ), (year, NN), (,, ,), (Help, NNP),...\n",
       "8    [[(First, RB), (post, NN), (in, IN), (quite, R...\n",
       "7    [[([, JJ), (Original, NNP), (Post, NNP), (], N...\n",
       "6    [[(I, PRP), (witnessed, VBD), (this, DT), (ast...\n",
       "5    [[(I, PRP), (work, VBP), (Helpdesk, NNP), (for...\n",
       "4    [[(This, DT), (just, RB), (happened, VBN), (.....\n",
       "3    [[(Another, DT), (tale, NN), (from, IN), (the,...\n",
       "2    [[([, JJ), (Part, NNP), (1, CD), (], NNP), ((,...\n",
       "1    [[(>, RB), ($, $), (Me, NNP), (-, :), (Hello, ...\n",
       "0    [[(So, RB), (my, PRP$), (story, NN), (starts, ...\n",
       "Name: POS_sents, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['POS_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And count the number of `NN` (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('password', 21),\n",
       " ('time', 14),\n",
       " ('lot', 12),\n",
       " ('computer', 12),\n",
       " ('life', 11),\n",
       " ('**Genius**', 10),\n",
       " ('email', 10),\n",
       " ('message', 9),\n",
       " ('system', 9),\n",
       " ('**Me**', 9),\n",
       " ('day', 9),\n",
       " ('today', 8),\n",
       " ('office', 8),\n",
       " ('part', 8),\n",
       " ('call', 8),\n",
       " ('story', 8),\n",
       " ('file', 7),\n",
       " ('work', 7),\n",
       " ('user', 7),\n",
       " ('problem', 7)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What about the number of top verbs (`VB`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 18),\n",
       " ('have', 17),\n",
       " ('get', 14),\n",
       " ('do', 11),\n",
       " ('make', 8),\n",
       " ('change', 8),\n",
       " ('say', 7),\n",
       " ('know', 6),\n",
       " ('send', 6),\n",
       " ('look', 6),\n",
       " ('tell', 6),\n",
       " ('help', 5),\n",
       " ('receive', 4),\n",
       " ('thank', 4),\n",
       " ('go', 4),\n",
       " ('remember', 4),\n",
       " ('call', 4),\n",
       " ('open', 4),\n",
       " ('take', 4),\n",
       " ('want', 4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'VB'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What about the adjectives that modify the word, \"computer\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'own', 'C-O-M-P-U-T-E-R.', 'unrestricted'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'computer'\n",
    "NResults = set()\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluating POS tagger\n",
    "\n",
    "We can check the POS tagger by running it on a manually tagged corpus and\n",
    "identifying a reasonable error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank = nltk.corpus.treebank\n",
    "treeBank.tagged_sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nltkTags = [nltk.pos_tag(s) for s in treeBank.sents()[:30]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And compare the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: publishing  \tStanford: NN\tTreebank: VBG\n",
      "Word: used  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: later  \tStanford: RB\tTreebank: JJ\n",
      "Word: New  \tStanford: NNP\tTreebank: JJ\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: Micronite  \tStanford: NNP\tTreebank: NN\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: heard  \tStanford: NN\tTreebank: VBD\n",
      "Word: asbestos  \tStanford: NNS\tTreebank: NN\n",
      "Word: replaced  \tStanford: VBD\tTreebank: VBN\n",
      "Word: worked  \tStanford: VBN\tTreebank: VBD\n",
      "Word: more  \tStanford: RBR\tTreebank: JJ\n",
      "Word: expected  \tStanford: JJ\tTreebank: VBN\n",
      "Word: study  \tStanford: NN\tTreebank: VBP\n",
      "Word: asbestos  \tStanford: JJ\tTreebank: NN\n",
      "Word: studied  \tStanford: VBD\tTreebank: VBN\n",
      "Word: Western  \tStanford: NNP\tTreebank: JJ\n",
      "Word: industrialized  \tStanford: JJ\tTreebank: VBN\n",
      "Word: Lorillard  \tStanford: NNP\tTreebank: NN\n",
      "Word: argue  \tStanford: NN\tTreebank: VBP\n",
      "Word: industrialized  \tStanford: JJ\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: asbestos  \tStanford: VB\tTreebank: NN\n",
      "Word: Areas  \tStanford: NNP\tTreebank: NNS\n",
      "Word: poured  \tStanford: VBN\tTreebank: VBD\n",
      "Word: in  \tStanford: IN\tTreebank: RP\n",
      "Word: mixed  \tStanford: JJ\tTreebank: VBD\n",
      "Word: clouds  \tStanford: NN\tTreebank: NNS\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: hung  \tStanford: NN\tTreebank: VBD\n",
      "Word: exhaust  \tStanford: JJ\tTreebank: NN\n",
      "The Precision is 95.269%\n"
     ]
    }
   ],
   "source": [
    "NumDiffs = 0\n",
    "for sentIndex in range(len(nltkTags)):\n",
    "    for wordIndex in range(len(nltkTags[sentIndex])):\n",
    "        if nltkTags[sentIndex][wordIndex][1] != treeBank.tagged_sents()[sentIndex][wordIndex][1]:\n",
    "            if treeBank.tagged_sents()[sentIndex][wordIndex][1] != '-NONE-':\n",
    "                print(\"Word: {}  \\tStanford: {}\\tTreebank: {}\".format(nltkTags[sentIndex][wordIndex][0], nltkTags[sentIndex][wordIndex][1], treeBank.tagged_sents()[sentIndex][wordIndex][1]))\n",
    "                NumDiffs += 1\n",
    "total = sum([len(s) for s in nltkTags])\n",
    "print(\"The Precision is {:.3f}%\".format((total-NumDiffs)/total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So we can see that the stanford POS tagger is quite good. Nevertheless, for a 20\n",
    "word sentence, we only have a 66% chance ($1-.96^{20}$) of tagging (and later\n",
    "parsing) it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trees = nltk.chunk.ne_chunk_sents(redditTopScores['POS_sents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
